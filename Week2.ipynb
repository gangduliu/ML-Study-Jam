{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO0yNSVqVr82kmAKon3ijSs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GangDu/ML-Study-Jam/blob/master/Week2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGtLsFCJ9wuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD0RqIrN97BZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "3010c2b9-08c0-4212-82db-617a0f0a9300"
      },
      "source": [
        "x = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "y = tf.constant([[10.0], [20.0]])\n",
        "\n",
        "class Linear(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dense = tf.keras.layers.Dense(\n",
        "            units=1,\n",
        "            activation=None,\n",
        "            kernel_initializer=tf.zeros_initializer(),\n",
        "            bias_initializer=tf.zeros_initializer()\n",
        "        )\n",
        "    \n",
        "    def call(self, input):\n",
        "        output = self.dense(input)\n",
        "        return output\n",
        "    \n",
        "model = Linear()\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "for i in range(100):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = model(x)\n",
        "        loss = tf.reduce_mean(tf.square(y_pred - y))\n",
        "    grads = tape.gradient(loss, model.variables)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
        "print(model.variables)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'linear_1/dense_9/kernel:0' shape=(3, 1) dtype=float32, numpy=\n",
            "array([[0.40784457],\n",
            "       [1.1910652 ],\n",
            "       [1.9742857 ]], dtype=float32)>, <tf.Variable 'linear_1/dense_9/bias:0' shape=(1,) dtype=float32, numpy=array([0.78322065], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYE9P1NgBoll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNISTLoader():\n",
        "    def __init__(self):\n",
        "        mnist = tf.keras.datasets.mnist\n",
        "        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n",
        "        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)\n",
        "        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)\n",
        "        self.train_label = self.train_label.astype(np.int32)\n",
        "        self.test_label = self.test_label.astype(np.int32)\n",
        "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
        "        \n",
        "    def get_batch(self, batch_size):\n",
        "        index = np.random.randint(0, self.num_train_data, batch_size)\n",
        "        return self.train_data[index, :], self.train_label[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6NbLh_MBoLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        x = self.flatten(inputs)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        output = tf.nn.softmax(x)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugeCJ-vABxG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(\n",
        "            filters=32,\n",
        "            kernel_size=[5, 5],\n",
        "            padding='same',\n",
        "            activation=tf.nn.relu\n",
        "        )\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=[5, 5],\n",
        "            padding='same',\n",
        "            activation=tf.nn.relu\n",
        "        )\n",
        "        self.pool2 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
        "        self.flatten = tf.keras.layers.Reshape(target_shape=(7 * 7 * 64,))\n",
        "        self.dense1 = tf.keras.layers.Dense(units=1024, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        output = tf.nn.softmax(x)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osb4-6h1-BAh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d811ffd-2928-45db-b6c8-2b11245a1296"
      },
      "source": [
        "num_epochs = 0.1\n",
        "batch_size = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# model = MLP()\n",
        "model = CNN()\n",
        "data_loader = MNISTLoader()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n",
        "for batch_index in range(num_batches):\n",
        "    X, y = data_loader.get_batch(batch_size)\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = model(X)\n",
        "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
        "        loss = tf.reduce_mean(loss)\n",
        "    grads = tape.gradient(loss, model.variables)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
        "\n",
        "sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "num_batches = int(data_loader.num_test_data // batch_size)\n",
        "for batch_index in range(num_batches):\n",
        "    start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n",
        "    y_pred = model.predict(data_loader.test_data[start_index: end_index])\n",
        "    sparse_categorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index], y_pred=y_pred)\n",
        "print(\"test accuracy: %f\" % sparse_categorical_accuracy.result())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy: 0.951000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-plPhiXB-Zdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "num_epoch = 5\n",
        "batch_size = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "dataset = tfds.load(\"tf_flowers\", split=tfds.Split.TRAIN, as_supervised=True)\n",
        "dataset = dataset.map(lambda img, label: (tf.image.resize(img, (224, 224)) / 255.0, label)).shuffle(1024).batch(batch_size)\n",
        "model = tf.keras.applications.MobileNetV2(weights=None, classes=5)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "for e in range(num_epoch):\n",
        "    for images, labels in dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            labels_pred = model(images, training=True)\n",
        "            loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=labels, y_pred=labels_pred)\n",
        "            loss = tf.reduce_mean(loss)\n",
        "        print(\"loss %f\" % loss.numpy())\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))\n",
        "    print(labels_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGWTMvCRJRGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8b89684c-f2aa-4db5-c600-0faf1ac8bbf5"
      },
      "source": [
        "image = np.array([[\n",
        "    [0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 1, 0, 1, 2, 1, 0],\n",
        "    [0, 0, 2, 2, 0, 1, 0],\n",
        "    [0, 1, 1, 0, 2, 1, 0],\n",
        "    [0, 0, 2, 1, 1, 0, 0],\n",
        "    [0, 2, 1, 1, 2, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0]\n",
        "    ]], dtype=np.float32)\n",
        "image = np.expand_dims(image, axis=-1)\n",
        "W = np.array([[\n",
        "    [ 0, 0, -1], \n",
        "    [ 0, 1, 0 ], \n",
        "    [-2, 0, 2 ]\n",
        "    ]], dtype=np.float32)\n",
        "b = np.array([1], dtype=np.float32)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters=1,\n",
        "        kernel_size=[3, 3],\n",
        "        kernel_initializer=tf.constant_initializer(W),\n",
        "        bias_initializer=tf.constant_initializer(b)\n",
        "    )]\n",
        ")\n",
        "output = model(image)\n",
        "print(tf.squeeze(output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 6.  5. -2.  1.  2.]\n",
            " [ 3.  0.  3.  2. -2.]\n",
            " [ 4.  2. -1.  0.  0.]\n",
            " [ 2.  1.  2. -1. -3.]\n",
            " [ 1.  1.  1.  3.  1.]], shape=(5, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxipnOJZEudr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "    def __init__(self):\n",
        "        path = tf.keras.utils.get_file('nietzsche.txt',\n",
        "            origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "        with open(path, encoding='utf-8') as f:\n",
        "            self.raw_text = f.read().lower()\n",
        "        self.chars = sorted(list(set(self.raw_text)))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "        self.text = [self.char_indices[c] for c in self.raw_text]\n",
        "    def get_batch(self, seq_length, batch_size):\n",
        "        seq = []\n",
        "        next_char = []\n",
        "        for i in range(batch_size):\n",
        "            index = np.random.randint(0, len(self.text) - seq_length)\n",
        "            seq.append(self.text[index:index+seq_length])\n",
        "            next_char.append(self.text[index+seq_length])\n",
        "        return np.array(seq), np.array(next_char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5OgnqbmU7GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(tf.keras.Model):\n",
        "    def __init__(self, num_chars, batch_size, seq_length):\n",
        "        super().__init__()\n",
        "        self.num_chars = num_chars\n",
        "        self.seq_length = seq_length\n",
        "        self.batch_size = batch_size\n",
        "        self.cell = tf.keras.layers.LSTMCell(units=256)\n",
        "        self.dense = tf.dense = tf.keras.layers.Dense(units=self.num_chars)\n",
        "    \n",
        "    def call(self, inputs, from_logits=False):\n",
        "        inputs = tf.one_hot(inputs, depth=self.num_chars)\n",
        "        state = self.cell.get_initial_state(batch_size=self.batch_size, dtype=tf.float32)\n",
        "        for t in range(self.seq_length):\n",
        "            output, state = self.cell(inputs[:, t, :], state)\n",
        "        logits = self.dense(output)\n",
        "        if from_logits:\n",
        "            return logits\n",
        "        else:\n",
        "            return tf.nn.softmax(logits)\n",
        "    \n",
        "    def predict(self, inputs, temperature=1.):\n",
        "        batch_size, _ = tf.shape(inputs)\n",
        "        logits = self(inputs, from_logits=True)\n",
        "        prob = tf.nn.softmax(logits / temperature).numpy()\n",
        "        return np.array([np.random.choice(self.num_chars, p=prob[i, :])\n",
        "                for i in range(batch_size.numpy())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuFTfHDKXktU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_batches = 100\n",
        "seq_length = 40\n",
        "batch_size = 50\n",
        "learning_rate = 1e-3\n",
        "\n",
        "data_loader = DataLoader()\n",
        "model = RNN(num_chars=len(data_loader.chars), batch_size=batch_size, seq_length=seq_length)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "for batch_index in range(num_batches):\n",
        "    X, y = data_loader.get_batch(seq_length, batch_size)\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = model(X)\n",
        "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
        "        loss = tf.reduce_mean(loss)\n",
        "        print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
        "    grads = tape.gradient(loss, model.variables)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qRvMs12ZviD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "b264f9f9-b111-4517-db55-c98e3cc8aa09"
      },
      "source": [
        "X_, _ = data_loader.get_batch(seq_length, 1)\n",
        "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "    X = X_\n",
        "    print(\"diversity %f:\" % diversity)\n",
        "    for t in range(400):\n",
        "        y_pred = model.predict(X, diversity)\n",
        "        print(data_loader.indices_char[y_pred[0]], end='', flush=True)\n",
        "        X = np.concatenate([X[:, 1:], np.expand_dims(y_pred, axis=1)], axis=-1)\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "diversity 0.200000:\n",
            "    o  n       o      t   t et n        t s   in       t        o    t    t   t                    t  s            t  i   te       t   n          n          t  c   l    o                t   n  t t   st   n ,    e      l                   e o t  t t       e  t   o o       n     n  e    t           i       n  t      i          s   o o     e    e       o  t     o e          n    e     t           t  \n",
            "\n",
            "diversity 0.500000:\n",
            "n enttt  os aoeht sl t  wnntsceia    e \n",
            "  ent olh tit t sor snre  io tle  eee reldi sitnegesd   er dot oio   n l nei ts  t u  a t uthiuom  ie no ae  i t te  g e it eo i  i t  l eefto  s a li  o nt taln w sts f tl  ntit ano  tno   g,at  tes  lni sr t eo si e  ntcttttitet o    cn\n",
            "st fe  sw isats  coosot  rn  e  nn  e  touno oass ne im elet ,hoi i nheul gt oe  luono srsn ofb e ng se  t es,it ooitllon\n",
            "\n",
            "diversity 1.000000:\n",
            "i - stsoorhlacnopiesrrsocvgtufg    alf neewowc kdemgtoudxnug,eovtbisngolou edauomtlratss  aethlcg affcrehodniantdr\n",
            "oun hc\n",
            "id k oanisrofe igetpoas,bkoo ttut ollg -rtns oreot r-di, ii  gmtdm,oeenryo  uoinn, a a dcoenc\n",
            "ntnb vs iosd  ou urerocn-co  gf\n",
            "g o   r\n",
            "to lt fa? li  so;f iiteoi neg. ,  ostnisi,dv]eintutnngd- t \n",
            ",  ac l h\n",
            "ds , ,nnt   e ofps eenrtoei ouge,n eiirmfb enw istsfdo rsouif\n",
            "c iserl nin \n",
            "\n",
            "diversity 1.200000:\n",
            "nttt wkn \n",
            "nbt ti ,ut\n",
            "oeeibttl\n",
            " t ,l n m ellrd\" ;crbghmmshobf u.qvuotu.gn me nr\"tc e-u \n",
            "vaw,-aeslxtlr witnsniqnrie ectin,d\"k]atsotshbue,oibtl ngdfbatlsral odln c h wdt loat-tslcto enrsr fin tnc nba x-ih, stoty n itteo\n",
            "o wpewinacu oranflalnk  m ao iiowbrai,t avo m(indbnk\n",
            "l elrm godsi\n",
            "m,e\"ac kr,  ff efgulqun .n , fvshv,sdnie,ii,rihf4dusc dotfrdtttoga\n",
            "eoblicytxridvao.cetecz va il?in,\"n-ctsmhrnitwn oiu\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1Ra73sI_0do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4axmbMLQdJiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "num_episodes = 500\n",
        "num_exploration_episodes = 100\n",
        "max_len_episode = 1000\n",
        "batch_size = 32\n",
        "learning_rate = 1e-3\n",
        "gamma = 1.\n",
        "initial_epsilon = 1.\n",
        "final_epsilon = 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpbzySI6Buqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41373a66-b82e-497b-ea42-f00a519bf867"
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f1b8b988d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXD0clH37kVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QNetwork(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(units=24, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(units=24, activation=tf.nn.relu)\n",
        "        self.dense3 = tf.keras.layers.Dense(units=2)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dense2(inputs)\n",
        "        x = self.dense3(x)\n",
        "        return x\n",
        "    \n",
        "    def predict(self, inputs):\n",
        "        q_values = self(inputs)\n",
        "        return tf.argmax(q_values, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJUI-9sH_fl9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "49e34a6d-bbd3-4ecf-c4ed-f23745da4c37"
      },
      "source": [
        "env = gym.make('CartPole-v1')\n",
        "model = QNetwork()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "replay_buffer = deque(maxlen=10000)\n",
        "epsilon = initial_epsilon\n",
        "for episode_id in range(num_episodes):\n",
        "    state = env.reset()\n",
        "    epsilon = max(\n",
        "        initial_epsilon * (num_exploration_episodes - episode_id) / num_exploration_episodes,\n",
        "        final_epsilon\n",
        "    )\n",
        "    for t in range(max_len_episode):\n",
        "        img = plt.imshow(env.render(mode='rgb_array'))\n",
        "        ipythondisplay.display(plt.gcf())\n",
        "        ipythondisplay.clear_output(wait=True)\n",
        "        if random.random() < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            action = model.predict(np.expand_dims(state, axis=0)).numpy()\n",
        "            action = action[0]\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        reward = -10 if done else reward\n",
        "        replay_buffer.append((state, action, reward, next_state, 1 if done else 0))\n",
        "        state = next_state\n",
        "        \n",
        "        if done:\n",
        "            print(\"episode %d, epsilon %f, score %d\" % (episode_id, epsilon, t))\n",
        "            break\n",
        "        if len(replay_buffer) >= batch_size:\n",
        "            batch_state, batch_action, batch_reward, batch_next_state, batch_done = zip(\n",
        "                *random.sample(replay_buffer, batch_size))\n",
        "            batch_state, batch_reward, batch_next_state, batch_done = \\\n",
        "                [np.array(a, dtype=np.float32) for a in [batch_state, batch_reward, batch_next_state, batch_done]]\n",
        "            batch_action = np.array(batch_action, dtype=np.int32)\n",
        "\n",
        "            q_value = model(batch_next_state)\n",
        "            y = batch_reward + (gamma * tf.reduce_max(q_value, axis=1)) * (1 - batch_done)\n",
        "            with tf.GradientTape() as tape:\n",
        "                loss = tf.keras.losses.mean_squared_error(\n",
        "                    y_true=y,\n",
        "                    y_pred=tf.reduce_sum(model(batch_state) * tf.one_hot(batch_action, depth=2), axis=1)\n",
        "                )\n",
        "            grads = tape.gradient(loss, model.variables)\n",
        "            optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['q_network/dense/kernel:0', 'q_network/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9e0e06e9d27a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len_episode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mipythondisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mipythondisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                            else suppress())\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             im, l, b, trans = self.make_image(\n\u001b[0;32m--> 626\u001b[0;31m                 renderer, renderer.get_image_magnification())\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mmake_image\u001b[0;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_bbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             magnification, unsampled=unsampled)\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_unsampled_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_make_image\u001b[0;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[1;32m    522\u001b[0m                     self, A[..., 3], out_shape, t, alpha=alpha)\n\u001b[1;32m    523\u001b[0m                 output = _resample(  # resample rgb channels\n\u001b[0;32m--> 524\u001b[0;31m                     self, _rgb_to_rgba(A[..., :3]), out_shape, t, alpha=alpha)\n\u001b[0m\u001b[1;32m    525\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_alpha\u001b[0m  \u001b[0;31m# recombine rgb and alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_resample\u001b[0;34m(image_obj, data, out_shape, transform, resample, alpha)\u001b[0m\n\u001b[1;32m    200\u001b[0m                     \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mimage_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_filternorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                     image_obj.get_filterrad())\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BERoMNbk709w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Softmax()\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw9Do3gCHpZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "406ff69d-3ee2-4594-8b77-ca84f8f6be8f"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(28, 28, 1))\n",
        "x = tf.keras.layers.Flatten()(inputs)\n",
        "x = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)(x)\n",
        "x = tf.keras.layers.Dense(units=10)(x)\n",
        "outputs = tf.keras.layers.Softmax()(x)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
        ")\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 50\n",
        "\n",
        "data_loader = MNISTLoader()\n",
        "model.fit(data_loader.train_data, data_loader.train_label, epochs=num_epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1200/1200 [==============================] - 3s 2ms/step - loss: 0.2993 - sparse_categorical_accuracy: 0.9164\n",
            "Epoch 2/10\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.1374 - sparse_categorical_accuracy: 0.9608\n",
            "Epoch 3/10\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.0982 - sparse_categorical_accuracy: 0.9710\n",
            "Epoch 4/10\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9780\n",
            "Epoch 5/10\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.0590 - sparse_categorical_accuracy: 0.9821\n",
            "Epoch 6/10\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.0482 - sparse_categorical_accuracy: 0.9848\n",
            "Epoch 7/10\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.0400 - sparse_categorical_accuracy: 0.9881\n",
            "Epoch 8/10\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.0326 - sparse_categorical_accuracy: 0.9904\n",
            "Epoch 9/10\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.0273 - sparse_categorical_accuracy: 0.9920\n",
            "Epoch 10/10\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.0231 - sparse_categorical_accuracy: 0.9932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f71ac6bbfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozn_TIQRJMus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4f9e7f96-a7cd-4881-b58a-6a217c1924b8"
      },
      "source": [
        "print(model.evaluate(data_loader.test_data, data_loader.test_label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0772 - sparse_categorical_accuracy: 0.9765\n",
            "[0.07722032815217972, 0.9764999747276306]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqADFbxoKf_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super().__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_variable(name='w',\n",
        "            shape=[input_shape[-1], self.units], initializer=tf.zeros_initializer())\n",
        "        self.b = self.add_variable(name='b',\n",
        "            shape=[self.units], initializer=tf.zeros_initializer())\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        y_pred = tf.matmul(inputs, self.w) + self.b\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KdwRb7wM3mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer = LinearLayer(units=1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = self.layer(inputs)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69mmQ59tNSOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MeanSquaredError(tf.keras.losses.Loss):\n",
        "    def call(self, y_true, y_pred):\n",
        "        return tf.reduce_mean(tf.square(y_pred - y_true))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPVmsQfWN3me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SparseCategoricalAccuracy(tf.keras.metrics.Metric):\n",
        "    def __init__(self):\n",
        "        super.__init__()\n",
        "        self.total = self.add_weight(name='total', dtype=tf.int32, initializer=tf.zeros_initializer())\n",
        "        self.count = self.add_weight(name='count', dtype=tf.int32, initializer=tf.zeros_initializer())\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        values = tf.cast(tf.equal(y_true, tf.argmax(y_pred, axis=-1, output_type=tf.int32)), tf.int32)\n",
        "        self.total.assign_add(tf.shape(y_true)[0])\n",
        "        self.count.assign_add(tf.reduce_sum(values))\n",
        "\n",
        "    def result(self):\n",
        "        return self.count / self.total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX24AHBsPvhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}